@article{rockova_mcalinn_2021, title={Dynamic Variable Selection with Spike-and-Slab Process Priors}, volume={16}, number={1}, journal={Bayesian Analysis}, author={Rockova, V. and McAlinn, K.}, year={2021}}

@article{KALLI2014779,
title = {Time-varying sparsity in dynamic regression models},
journal = {Journal of Econometrics},
volume = {178},
number = {2},
pages = {779-793},
year = {2014},
issn = {0304-4076},
author = {Kalli, M. and Griffin, J. E.},
keywords = {Time-varying regression, Shrinkage priors, Normal-gamma priors, Markov chain Monte Carlo, Equity premium, Inflation},
abstract = {A novel Bayesian method for inference in dynamic regression models is proposed where both the values of the regression coefficients and the importance of the variables are allowed to change over time. We focus on forecasting and so the parsimony of the model is important for good performance. A prior is developed which allows the shrinkage of the regression coefficients to suitably change over time and an efficient Markov chain Monte Carlo method for posterior inference is described. The new method is applied to two forecasting problems in econometrics: equity premium prediction and inflation forecasting. The results show that this method outperforms current competing Bayesian methods.}
}

@article{Nakajima2013a,
author = { Nakajima, J.  and  West, M.},
title = {Bayesian Analysis of Latent Threshold Dynamic Models},
journal = {Journal of Business \& Economic Statistics},
volume = {31},
number = {2},
pages = {151-164},
year  = {2013},
publisher = {Taylor & Francis}
}

@article{bitto_fruhwirth-schnatter_2019, title={Achieving shrinkage in a time-varying parameter model framework}, volume={210},journal={Journal of Econometrics}, author={Bitto, A. and Fruhwirth-Schnatter, S.}, year={2019}, pages={75-97}}


@article{G_1986b, title={Minimax multiple shrinkage estimation}, volume={14}, DOI={}, number={1}, journal={The Annals of Statistics}, author={George, E. I.}, year={1986b}}

@article{G_1986a, title={Combining minimax shrinkage estimators}, volume={81}, DOI={}, number={394}, journal={Journal of the American Statistical Association}, author={George, E. I.}, year={1986a}}

@article{Durbin_K2002,
 ISSN = {00063444},
 abstract = {A simulation smoother in state space time series analysis is a procedure for drawing samples from the conditional distribution of state or disturbance vectors given the observations. We present a new technique for this which is both simple and computationally efficient. The treatment includes models with diffuse initial conditions and regression effects. Computational comparisons are made with the previous standard method. Two applications are provided to illustrate the use of the simulation smoother for Gibbs sampling for Bayesian inference and importance sampling for classical inference.},
 author = {Durbin, J. and Koopman, S. J.},
 journal = {Biometrika},
 number = {3},
 pages = {603-615},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {A Simple and Efficient Simulation Smoother for State Space Time Series Analysis},
 volume = {89},
 year = {2002}
}

@article{CK_1994,
 ISSN = {00063444},
 abstract = {We show how to use the Gibbs sampler to carry out Bayesian inference on a linear state space model with errors that are a mixture of normals and coefficients that can switch over time. Our approach simultaneously generates the whole of the state vector given the mixture and coefficient indicator variables and simultaneously generates all the indicator variables conditional on the state vectors. The states are generated efficiently using the Kalman filter. We illustrate our approach by several examples and empirically compare its performance to another Gibbs sampler where the states are generated one at a time. The empirical results suggest that our approach is both practical to implement and dominates the Gibbs sampler that generates the states one at a time.},
 author = {Carter, C. K. and Kohn, R.},
 journal = {Biometrika},
 number = {3},
 pages = {541--553},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {On Gibbs Sampling for State Space Models},
 volume = {81},
 year = {1994}
}

@article{fruhwirth-schnatter_1994, title={Data Augmentation And Dynamic Linear Models}, volume={15}, number={2}, journal={Journal of Time Series Analysis}, author={Fruhwirth-Schnatter, S.}, year={1994}, pages={183-202}}

@article{chan_jeliazkov_2009, title={Efficient simulation and integrated likelihood estimation in state space models}, volume={1}, number={1/2}, journal={International Journal of Mathematical Modelling and Numerical Optimisation}, author={Chan, J. and Jeliazkov, I.}, year={2009}, pages={101}}

@article{EJC_2016,
author = {Eisenstat, E. and Chan, J. and Strachan, R.},
year = {2014},
month = {01},
pages = {},
title = {Stochastic Model Specification Search for Time-Varying Parameter VARs},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2403560}
}


@article{S_1994,
 ISSN = {00063444},
 abstract = {In this paper we suggest the use of simulation techniques to extend the applicability of the usual Gaussian state space filtering and smoothing techniques to a class of non-Gaussian time series models. This allows a fully Bayesian or maximum likelihood analysis of some interesting models, including outlier models, discrete Markov chain components, multiplicative models and stochastic variance models. Finally we discuss at some length the use of a non-Gaussian model to seasonally adjust the published money supply figures.},
 author = {Shephard, N.},
 journal = {Biometrika},
 number = {1},
 pages = {115--131},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Partial Non-Gaussian State Space},
 volume = {81},
 year = {1994}
}

@article{scott_varian_2013, title={Predicting the Present with Bayesian Structural Time Series}, journal={SSRN Electronic Journal}, author={Scott, S. L. and Varian, H. R.}, year={2013}}


@article{zellner_1986, title={On Assessing Prior Distributions and Bayesian Regression Analysis with g-Prior Distributions}, journal={Bayesian Inference and Decision Techniques: Essays in Honor of Bruno de Finetti}, author={Zellner, A.}, year={1986}}

@book{KC_2014, title={Statistical Modeling and Computation}, author={Kroese, D. P. and Chan, J. C.}, publisher = {Springer, New
York, 2014.}, year={2014}}

@article{varian_choi_2009, title={Predicting the Present with Google Trends}, journal={SSRN Electronic Journal}, author={Varian, H. and Choi, H.}, year={2009}}

@misc{ning2021mbsts,
      title={The mbsts package: Multivariate Bayesian Structural Time Series Models in R}, 
      author={Ning, N. and Qiu, J.},
      year={2021},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{petris_petrone_campagnoli_2009, title={Dynamic linear models}, journal={Dynamic Linear Models with R}, author={Petris, G. and Petrone, S. and Campagnoli, P.}, year={2009}, pages={31-84}}

@article{T_1996,
 ISSN = {00359246},
 abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
 author = {Tibshirani, R.},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {267--288},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Regression Shrinkage and Selection via the Lasso},
 volume = {58},
 year = {1996}
}

@article{PC_2008,
author = {Park, T. and Casella, G.},
title = {The Bayesian Lasso},
journal = {Journal of the American Statistical Association},
volume = {103},
number = {482},
pages = {681-686},
year  = {2008},
publisher = {Taylor & Francis}
}


@article{G_1995,
 ISSN = {00063444},
 abstract = {Markov chain Monte Carlo methods for Bayesian computation have until recently been restricted to problems where the joint distribution of all variables has a density with respect to some fixed standard underlying measure. They have therefore not been available for application to Bayesian model determination, where the dimensionality of the parameter vector is typically not fixed. This paper proposes a new framework for the construction of reversible Markov chain samplers that jump between parameter subspaces of differing dimensionality, which is flexible and entirely constructive. It should therefore have wide applicability in model determination problems. The methodology is illustrated with applications to multiple change-point analysis in one and two dimensions, and to a Bayesian comparison of binomial experiments.},
 author = {Green, P. J.},
 journal = {Biometrika},
 number = {4},
 pages = {711--732},
 publisher = {[Oxford University Press, Biometrika Trust]},
 title = {Reversible Jump Markov Chain Monte Carlo Computation and Bayesian Model Determination},
 volume = {82},
 year = {1995}
}

@misc{fan2010reversible,
      title={Reversible jump Markov chain Monte Carlo}, 
      author={Fan, Y. and Sisson, S. A.},
      year={2010},
      archivePrefix={arXiv}
}

@article{MB_1988,
author = {Mitchell, T. J. and  Beauchamp, J. J. },
title = {Bayesian Variable Selection in Linear Regression},
journal = {Journal of the American Statistical Association},
volume = {83},
number = {404},
pages = {1023-1032},
year  = {1988},
publisher = {Taylor & Francis}
}

@article{GM_1993,
 ISSN = {01621459},
 abstract = {A crucial problem in building a multiple regression model is the selection of predictors to include. The main thrust of this article is to propose and develop a procedure that uses probabilistic considerations for selecting promising subsets. This procedure entails embedding the regression setup in a hierarchical normal mixture model where latent variables are used to identify subset choices. In this framework the promising subsets of predictors can be identified as those with higher posterior probability. The computational burden is then alleviated by using the Gibbs sampler to indirectly sample from this multinomial posterior distribution on the set of possible subset choices. Those subsets with higher probability--the promising ones--can then be identified by their more frequent appearance in the Gibbs sample.},
 author = {George, E. I. and McCulloch, R. E.},
 journal = {Journal of the American Statistical Association},
 number = {423},
 pages = {881--889},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title = {Variable Selection Via Gibbs Sampling},
 volume = {88},
 year = {1993}
}

@article{GM_1997,
 ISSN = {10170405, 19968507},
 abstract = {This paper describes and compares various hierarchical mixture prior formulations of variable selection uncertainty in normal linear regression models. These include the nonconjugate SSVS formulation of George and McCulloch (1993), as well as conjugate formulations which allow for analytical simplification. Hyperparameter settings which base selection on practical significance, and the implications of using mixtures with point priors are discussed. Computational methods for posterior evaluation and exploration are considered. Rapid updating methods are seen to provide feasible methods for exhaustive evaluation using Gray Code sequencing in moderately sized problems, and fast Markov Chain Monte Carlo exploration in large problems. Estimation of normalization constants is seen to provide improved posterior estimates of individual model probabilities and the total visited probability. Various procedures are illustrated on simulated sample problems and on a real problem concerning the construction of financial index tracking portfolios.},
 author = {George, E. I. and McCulloch, R. E.},
 journal = {Statistica Sinica},
 number = {2},
 pages = {339--373},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {Approaches For Bayesian Variable Selection},
 volume = {7},
 year = {1997}
}

@article{OS_2009,
author = {O'Hara, R. B. and Sillanpää, M. J.},
title = {{A review of Bayesian variable selection methods: what, how and which}},
volume = {4},
journal = {Bayesian Analysis},
number = {1},
publisher = {International Society for Bayesian Analysis},
pages = {85 -- 117},
keywords = {BUGS, MCMC, Variable selection},
year = {2009}
}

@article{R_2013,
author = {Rockova, V.},
title = {{Bayesian Variable Selection in High-dimensional Applications}},
year = {2013},
ISBN = {978-90-9027731-8}
}

@article{WL_2000,
 ISSN = {13697412, 14679868},
 abstract = {We generalize the Gaussian mixture transition distribution (GMTD) model introduced by Le and co-workers to the mixture autoregressive (MAR) model for the modelling of non-linear time series. The models consist of a mixture of K stationary or non-stationary AR components. The advantages of the MAR model over the GMTD model include a more full range of shape changing predictive distributions and the ability to handle cycles and conditional heteroscedasticity in the time series. The stationarity conditions and autocorrelation function are derived. The estimation is easily done via a simple EM algorithm and the model selection problem is addressed. The shape changing feature of the conditional distributions makes these models capable of modelling time series with multimodal conditional distributions and with heteroscedasticity. The models are applied to two real data sets and compared with other competing models. The MAR models appear to capture features of the data better than other competing models do.},
 author = {Wong, C. S. and Li, W. K.},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {1},
 pages = {95--115},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {On a Mixture Autoregressive Model},
 volume = {62},
 year = {2000}
}


@article{RM_2020, title={Dynamic Variable Selection with Spike-and-Slab
Process Priors - Supplementary Material.}, journal={Bayesian Analysis}, author={Rockova, V. and McAlinn, K.}, year={2021}}

@book{WH_1997,
author = {West, M. and Harrison, J.},
title = {Bayesian Forecasting and Dynamic Models (2nd Ed.)},
year = {1997},
isbn = {0387947256},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@article{KSC_1998,
 ISSN = {00346527, 1467937X},
 abstract = {In this paper, Markov chain Monte Carlo sampling methods are exploited to provide a unified, practical likelihood-based framework for the analysis of stochastic volatility models. A highly effective method is developed that samples all the unobserved volatilities at once using an approximating offset mixture model, followed by an importance reweighting procedure. This approach is compared with several alternative methods using real data. The paper also develops simulation-based methods for filtering, likelihood evaluation and model failure diagnostics. The issue of model choice using non-nested likelihood ratios and Bayes factors is also investigated. These methods are used to compare the fit of stochastic volatility and GARCH models. All the procedures are illustrated in detail.},
 author = {Kim, S. and Shephard, N. and Chib, S.},
 journal = {The Review of Economic Studies},
 number = {3},
 pages = {361--393},
 publisher = {[Oxford University Press, Review of Economic Studies, Ltd.]},
 title = {Stochastic Volatility: Likelihood Inference and Comparison with ARCH Models},
 volume = {65},
 year = {1998}
}

@article{KASTNER2014408,
title = {Ancillarity-sufficiency interweaving strategy (ASIS) for boosting MCMC estimation of stochastic volatility models},
journal = {Computational Statistics and Data Analysis},
volume = {76},
pages = {408-423},
year = {2014},
note = {CFEnetwork: The Annals of Computational and Financial Econometrics},
issn = {0167-9473},
author = {Kastner, G. and Frühwirth-Schnatter, S.},
keywords = {Markov chain Monte Carlo, Non-centering, Auxiliary mixture sampling, Massively parallel computing, State space model, Exchange rate data},
abstract = {Bayesian inference for stochastic volatility models using MCMC methods highly depends on actual parameter values in terms of sampling efficiency. While draws from the posterior utilizing the standard centered parameterization break down when the volatility of volatility parameter in the latent state equation is small, non-centered versions of the model show deficiencies for highly persistent latent variable series. The novel approach of ancillarity-sufficiency interweaving has recently been shown to aid in overcoming these issues for a broad class of multilevel models. It is demonstrated how such an interweaving strategy can be applied to stochastic volatility models in order to greatly improve sampling efficiency for all parameters and throughout the entire parameter range. Moreover, this method of “combining best of different worlds” allows for inference for parameter constellations that have previously been infeasible to estimate without the need to select a particular parameterization beforehand.}
}

@article{SV_2016,
 title={Dealing with Stochastic Volatility in Time Series Using the R Package stochvol},
 volume={69},
 abstract={The R package stochvol provides a fully Bayesian implementation of heteroskedasticity modeling within the framework of stochastic volatility. It utilizes Markov chain Monte Carlo (MCMC) samplers to conduct inference by obtaining draws from the posterior distribution of parameters and latent variables which can then be used for predicting future volatilities. The package can straightforwardly be employed as a stand-alone tool; moreover, it allows for easy incorporation into other MCMC samplers. The main focus of this paper is to show the functionality of stochvol. In addition, it provides a brief mathematical description of the model, an overview of the sampling schemes used, and several illustrative examples using exchange rate data.},
 number={5},
 journal={Journal of Statistical Software},
 author={Kastner, G.},
 year={2016},
 pages={1–30}
}

@article{Chan_2018,
author = {Chan, J. and Eisenstat, E.},
title = {Bayesian model comparison for time-varying parameter VARs with stochastic volatility},
journal = {Journal of Applied Econometrics},
volume = {33},
number = {4},
pages = {509-532},
abstract = {Summary We develop importance sampling methods for computing two popular Bayesian model comparison criteria, namely, the marginal likelihood and the deviance information criterion (DIC) for time-varying parameter vector autoregressions (TVP-VARs), where both the regression coefficients and volatilities are drifting over time. The proposed estimators are based on the integrated likelihood, which are substantially more reliable than alternatives. Using US data, we find overwhelming support for the TVP-VAR with stochastic volatility compared to a conventional constant coefficients VAR with homoskedastic innovations. Most of the gains, however, appear to have come from allowing for stochastic volatility rather than time variation in the VAR coefficients or contemporaneous relationships. Indeed, according to both criteria, a constant coefficients VAR with stochastic volatility outperforms the more general model with time-varying parameters.},
year = {2018}
}



@article{MCCAUSLAND2011199,
title = {Simulation smoothing for state–space models: A computational efficiency analysis},
journal = {Computational Statistics and Data Analysis},
volume = {55},
number = {1},
pages = {199-212},
year = {2011},
issn = {0167-9473},
author = {McCausland, W. J. and Miller, S. and Pelletier, D.},
keywords = {State–space models, Markov chain Monte Carlo, Importance sampling, Count data, High frequency financial data},
abstract = {Simulation smoothing involves drawing state variables (or innovations) in discrete time state–space models from their conditional distribution given parameters and observations. Gaussian simulation smoothing is of particular interest, not only for the direct analysis of Gaussian linear models, but also for the indirect analysis of more general models. Several methods for Gaussian simulation smoothing exist, most of which are based on the Kalman filter. Since states in Gaussian linear state–space models are Gaussian Markov random fields, it is also possible to apply the Cholesky Factor Algorithm (CFA) to draw states. This algorithm takes advantage of the band diagonal structure of the Hessian matrix of the log density to make efficient draws. We show how to exploit the special structure of state–space models to draw latent states even more efficiently. We analyse the computational efficiency of Kalman-filter-based methods, the CFA, and our new method using counts of operations and computational experiments. We show that for many important cases, our method is most efficient. Gains are particularly large for cases where the dimension of observed variables is large or where one makes repeated draws of states for the same parameter values. We apply our method to a multivariate Poisson model with time-varying intensities, which we use to analyse financial market transaction count data.}
}

@article{YM_2011,
author = {Yu, Y. and Meng, X.},
title = {To Center or Not to Center: That Is Not the Question—An Ancillarity–Sufficiency Interweaving Strategy (ASIS) for Boosting MCMC Efficiency},
journal = {Journal of Computational and Graphical Statistics},
volume = {20},
number = {3},
pages = {531-570},
year  = {2011},
publisher = {Taylor & Francis}
}


@Article{Belmonte,
  author={Belmonte, M. A. G. and Koop, G. and Korobilis, D.},
  title={{Hierarchical Shrinkage in Time‐Varying Parameter Models}},
  journal={Journal of Forecasting},
  year=2014,
  volume={33},
  number={1},
  pages={80-94},
  month={January}
}

@misc{bitto2018achieving,
      title={Achieving Shrinkage in a Time-Varying Parameter Model Framework}, 
      author={Bitto, A. and Frühwirth-Schnatter, S.},
      year={2018},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{RG_2014,
author = {Rockova, V. and George, E. I.},
title = {EMVS: The EM Approach to Bayesian Variable Selection},
journal = {Journal of the American Statistical Association},
volume = {109},
number = {506},
pages = {828-846},
year  = {2014},
publisher = {Taylor & Francis}
}

@article{GDW_2004,
title = {Monte Carlo Smoothing for Nonlinear Time Series},
author = {Godsill, S. J. and Doucet, A. and West, M.},
year = {2004},
journal = {Journal of the American Statistical Association},
volume = {99},
pages = {156-168}
}

@inproceedings{LW_2001,
  title={Combined Parameter and State Estimation in Simulation-Based Filtering},
  author={Liu, J. and West, M.},
  booktitle={Sequential Monte Carlo Methods in Practice},
  year={2001}
}

@article{SIMS_1980,
 ISSN = {00129682, 14680262},
 author = {Sims, C. A.},
 journal = {Econometrica},
 number = {1},
 pages = {1--48},
 publisher = {[Wiley, Econometric Society]},
 title = {Macroeconomics and Reality},
 volume = {48},
 year = {1980}
}

@ARTICLE{CANOVA_1993,
title = {Trade interdependence and the international business cycle},
author = {Canova, Fabio and Dellas, Harris},
year = {1993},
journal = {Journal of International Economics},
volume = {34},
number = {1-2},
pages = {23-47}
}

@article{CS_2001,
 ISSN = {08893365, 15372642},
 author = {Stock, J. H.},
 journal = {NBER Macroeconomics Annual},
 pages = {379--387},
 publisher = {University of Chicago Press},
 title = {Evolving Post-World War II U.S. Inflation Dynamics},
 volume = {16},
 year = {2001}
}

@article{COGLEY2005262,
title = {Drifts and volatilities: monetary policies and outcomes in the post WWII US},
journal = {Review of Economic Dynamics},
volume = {8},
number = {2},
pages = {262-302},
year = {2005},
note = {Monetary Policy and Learning},
issn = {1094-2025},
author = {Cogley, T. and Sargent, T. J.},
abstract = {For a VAR with drifting coefficients and stochastic volatilities, we present posterior densities for several objects that are pertinent for designing and evaluating monetary policy. These include measures of inflation persistence, the natural rate of unemployment, a core rate of inflation, and ‘activism coefficients’ for monetary policy rules. Our posteriors imply substantial variation of all of these objects for post WWII US data. After adjusting for changes in volatility, persistence of inflation increases during the 1970s, then falls in the 1980s and 1990s. Innovation variances change systematically, being substantially larger in the late 1970s than during other times. Measures of uncertainty about core inflation and the degree of persistence covary positively. We use our posterior distributions to evaluate the power of several tests that have been used to test the null hypothesis of time-invariance of autoregressive coefficients of VARs against the alternative of time-varying coefficients. Except for one, we find that those tests have low power against the form of time variation captured by our model.}
}

@article{Primicieri_2005,
 ISSN = {00346527, 1467937X},
 abstract = {Monetary policy and the private sector behaviour of the U.S. economy are modelled as a time varying structural vector autoregression, where the sources of time variation are both the coefficients and the variance covariance matrix of the innovations. The paper develops a new, simple modelling strategy for the law of motion of the variance covariance matrix and proposes an efficient Markov chain Monte Carlo algorithm for the model likelihood/posterior numerical evaluation. The main empirical conclusions are: (1) both systematic and non-systematic monetary policy have changed during the last 40 years-in particular, systematic responses of the interest rate to inflation and unemployment exhibit a trend toward a more aggressive behaviour, despite remarkable oscillations; (2) this has had a negligible effect on the rest of the economy. The role played by exogenous non-policy shocks seems more important than interest rate policy in explaining the high inflation and unemployment episodes in recent U.S. economic history.},
 author = {Primiceri, G. E.},
 journal = {The Review of Economic Studies},
 number = {3},
 pages = {821--852},
 publisher = {[Oxford University Press, Review of Economic Studies, Ltd.]},
 title = {Time Varying Structural Vector Autoregressions and Monetary Policy},
 volume = {72},
 year = {2005}
}

@article{CV_2009,
author = {Varian, H. and Choi, H.},
year = {2009},
month = {04},
pages = {},
title = {Predicting the Present with Google Trends},
volume = {88},
journal = {Economic Record}
}

@article{Korob_VAR,
 ISSN = {08837252, 10991255},
 abstract = {This paper develops methods for automatic selection of variables in Bayesian vector autoregressions (VARs) using the Gibbs sampler. In particular, I provide computationally efficient algorithms for stochastic variable selection in generic linear and nonlinear models, as well as models of large dimensions. The performance of the proposed variable selection method is assessed in forecasting three major macroeconomic time series of the UK economy. Data-based restrictions of VAR coefficients can help improve upon their unrestricted counterparts in forecasting, and in many cases they compare favorably to shrinkage estimators.},
 author = {Korobilis, D.},
 journal = {Journal of Applied Econometrics},
 number = {2},
 pages = {204--230},
 publisher = {Wiley},
 title = {VAR Forecasting using Bayesian Variable Selection},
 volume = {28},
 year = {2013}
}

@Article{TIDYVERSE,
    title = {Welcome to the {tidyverse}},
    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and
      Winston Chang and Lucy D'Agostino McGowan and Romain François and
      Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester
      and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan
      Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson
      and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and
      Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},
    year = {2019},
    journal = {Journal of Open Source Software},
    volume = {4},
    number = {43},
    pages = {1686}
  }

@Article{DLM,
    title = {An {R} Package for Dynamic Linear Models},
    author = {Petris, G.},
    journal = {Journal of Statistical Software},
    year = {2010},
    volume = {36},
    number = {12},
    pages = {1--16}
    }
  
   @Book{MASS,
    title = {Modern Applied Statistics with S},
    author = {Venables, W. N. and Ripley, B. D.},
    publisher = {Springer},
    edition = {Fourth},
    address = {New York},
    year = {2002},
    note = {ISBN 0-387-95457-0}
  }

@Article{FREDMD,
  author={McCracken, M. W. and Ng, S.},
  title={{FRED-MD: A Monthly Database for Macroeconomic Research}},
  journal={Journal of Business \& Economic Statistics},
  year=2016,
  volume={34},
  number={4},
  pages={574-589},
  month={October},
  keywords={},
  abstract={ This article describes a large, monthly frequency, macroeconomic database with the goal of establishing a convenient starting point for empirical analysis that requires “big data.” The dataset mimics the coverage of those already used in the literature but has three appealing features. First, it is designed to be updated monthly using the Federal Reserve Economic Data (FRED) database. Second, it will be publicly accessible, facilitating comparison of related research and replication of empirical work. Third, it will relieve researchers from having to manage data changes and revisions. We show that factors extracted from our dataset share the same predictive content as those based on various vintages of the so-called Stock–Watson dataset. In addition, we suggest that diffusion indexes constructed as the partial sum of the factor estimates can potentially be useful for the study of business cycle chronology. Supplementary materials for this article are available online.}
}

@Article{FREDQD,
  author={Michael W. McCracken and Serena Ng},
  title={{FRED-QD: A Quarterly Database for Macroeconomic Research}},
  journal={Review},
  year=2021,
  volume={103},
  number={1},
  pages={1-44},
  month={January},
  keywords={}
}

@INCOLLECTION{GOOGLE_TRENDS,
title = {Macroeconomic Nowcasting Using Google Probabilities},
author = {Koop, G. and Onorante, L.},
year = {2019},
pages = {17-40},
booktitle = {Topics in Identification, Limited Dependent Variables, Partial Observability, Experimentation, and Flexible Modeling: Part A},
volume = {40A},
publisher = {Emerald Publishing Ltd},
abstract = {Abstract Many recent chapters have investigated whether data from internet search engines such as Google can help improve nowcasts or short-term forecasts of macroeconomic variables. These chapters construct variables based on Google searches and use them as explanatory variables in regression models. We add to this literature by nowcasting using dynamic model selection (DMS) methods which allow for model switching between time-varying parameter regression models. This is potentially useful in an environment of coefficient instability and over-parameterization which can arise when forecasting with Google variables. We extend the DMS methodology by allowing for the model switching to be controlled by the Google variables through what we call “Google probabilities”: instead of using Google variables as regressors, we allow them to determine which nowcasting model should be used at each point in time. In an empirical exercise involving nine major monthly US macroeconomic variables, we find DMS methods to provide large improvements in nowcasting. Our use of Google model probabilities within DMS often performs better than conventional DMS methods.},
keywords = {Google; Dynamic Model Averaging; internet search data; nowcasting; state space model; time varying parameter model}
}

@article{CR_2015,
 abstract = {This paper compares alternative models of time-varying volatility on the basis of the accuracy of real-time point and density forecasts of key macroeconomic time series for the USA. We consider Bayesian autoregressive and vector autoregressive models that incorporate some form of time-varying volatility, precisely random walk stochastic volatility, stochastic volatility following a stationary AR process, stochastic volatility coupled with fat tails, GARCH and mixture of innovation models. The results show that the AR and VAR specifications with conventional stochastic volatility dominate other volatility specifications, in terms of point forecasting to some degree and density forecasting to a greater degree.},
 author = {Clark, T. E. and Ravazzolo, F.},
 journal = {Journal of Applied Econometrics},
 number = {4},
 pages = {551--575},
 publisher = {Wiley},
 title = {Macroeconomic forecasting performance under alternative specifications of time-varying volatility},
 volume = {30},
 year = {2015}
}

@article{AM_1974,
 ISSN = {00359246},
 author = {Andrews, D. F. and Mallows, C. L.},
 journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
 number = {1},
 pages = {99--102},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Scale Mixtures of Normal Distributions},
 volume = {36},
 year = {1974}
}

@misc{legramanti2020bayesian,
      title={Bayesian cumulative shrinkage for infinite factorizations}, 
      author={Legramanti, S. and Durante, D. and Dunson, D.B},
      year={2020},
      archivePrefix={arXiv}
}

@article{Woodburry,
 ISSN = {00361445},
 abstract = {The Sherman--Morrison--Woodbury formulas relate the inverse of a matrix after a small-rank perturbation to the inverse of the original matrix. The history of these formulas is presented and various applications to statistics, networks, structural analysis, asymptotic analysis, optimization, and partial differential equations are discussed. The Sherman--Morrison--Woodbury formulas express the inverse of a matrix after a small rank perturbation in terms of the inverse of the original matrix. This paper surveys the history of these formulas and we examine some applications where these formulas are helpful.},
 author = {William, W. H.},
 journal = {SIAM Review},
 number = {2},
 pages = {221--239},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {Updating the Inverse of a Matrix},
 volume = {31},
 year = {1989}
}

@article{CP_2020,
author = {Chopin, N. and Papaspiliopoulos, O.},
year = {2020},
month = {01},
pages = {},
title = {An Introduction to Sequential Monte Carlo},
isbn = {978-3-030-47844-5}
}
